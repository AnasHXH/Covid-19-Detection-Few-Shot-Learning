{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Classification\n",
    "\n",
    "In this notebook, we have implemented baseline models to compare the accuracy of our proposed approach\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Transfer Learning\n",
    "3. Convolutional Neural Networks\n",
    "\n",
    "we have also taken their last layer embeddings to analyse the decision boundaries using clustering approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.7/site-packages (4.5.1.48)\r\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/anaconda3/lib/python3.7/site-packages (from opencv-python) (1.18.4)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uezm2gZUgajw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "base_dir = './Covid19-dataset/'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Directory with our training cat/dog pictures\n",
    "train_covid_dir = os.path.join(train_dir, 'Covid')\n",
    "train_normal_dir = os.path.join(train_dir, 'Normal')\n",
    "train_pneumonia_dir = os.path.join(train_dir, 'Viral Pneumonia')\n",
    "\n",
    "# Directory with our validation cat/dog pictures\n",
    "validation_covid_dir = os.path.join(validation_dir, 'Covid')\n",
    "validation_normal_dir = os.path.join(validation_dir, 'Normal')\n",
    "validation_pneumonia_dir = os.path.join(validation_dir, 'Viral Pneumonia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ew8qy3DrzFo2",
    "outputId": "474c58c7-625a-4751-c458-2b7acde5ca4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "train_covid_fnames = os.listdir(train_covid_dir)\n",
    "train_normal_fnames = os.listdir(train_normal_dir)\n",
    "train_pneumonia_fnames = os.listdir(train_pneumonia_dir)\n",
    "\n",
    "print (len(train_covid_fnames)+len(train_normal_fnames)+len(train_pneumonia_fnames))\n",
    "print (len(os.listdir(validation_covid_dir))+len(os.listdir(validation_normal_dir))+len(os.listdir(validation_pneumonia_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EiQPzZq10JU0"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "\n",
    "nrows = 6\n",
    "ncols = 4\n",
    "\n",
    "pic_index = 0 # Index for iterating over images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 224, 224, 3)\n",
      "(51, 224, 224, 3)\n",
      "(200, 3)\n",
      "(51, 3)\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "BASE_DATA_FOLDER = \"./Covid19-dataset\"\n",
    "TRAin_DATA_FOLDER = os.path.join(BASE_DATA_FOLDER, \"train\")\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for class_folder_name in os.listdir(TRAin_DATA_FOLDER):\n",
    "    class_folder_path = os.path.join(TRAin_DATA_FOLDER, class_folder_name)\n",
    "    for image_path in glob(os.path.join(class_folder_path, \"*.jpeg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        #image = cv2.resize(image, (150, 150))\n",
    "        #image = segment_plant(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (224,224))\n",
    "        image = np.stack((image,)*3, axis=-1)\n",
    "#         image = image.flatten()\n",
    "        \n",
    "        images.append(image)\n",
    "        labels.append(class_folder_name)\n",
    "    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        #image = cv2.resize(image, (150, 150))\n",
    "        #image = segment_plant(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (224,224))\n",
    "        image = np.stack((image,)*3, axis=-1)\n",
    "        \n",
    "#         image = image.flatten()\n",
    "        \n",
    "        images.append(image)\n",
    "        labels.append(class_folder_name)\n",
    "    for image_path in glob(os.path.join(class_folder_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        #image = cv2.resize(image, (150, 150))\n",
    "        #image = segment_plant(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (224,224))\n",
    "        image = np.stack((image,)*3, axis=-1)\n",
    "        \n",
    "#         image = image.flatten()\n",
    "        \n",
    "        images.append(image)\n",
    "        labels.append(class_folder_name)\n",
    "        \n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "\n",
    "# print (labels)\n",
    "from sklearn import preprocessing\n",
    "pre = preprocessing.LabelEncoder()\n",
    "pre.fit(labels)\n",
    "labels_numeric = pre.transform(labels)\n",
    "Num_Class = 3\n",
    "\n",
    "def OneHotEncoded(y_train):\n",
    "    y_t=np.zeros((len(y_train),Num_Class), dtype=int)\n",
    "    for i,x in enumerate(y_train):\n",
    "        y_t[i][int(x)-1]=1\n",
    "    return y_t\n",
    "# print (labels)\n",
    "\n",
    "labels = OneHotEncoded(labels_numeric)\n",
    "\n",
    "X_train, X_test= train_test_split(images, test_size=0.2, random_state=42)\n",
    "y_train, y_test= train_test_split(labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# print (labels_numeric)\n",
    "\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)\n",
    "X_train = X_train.reshape(200, 224, 224, 3)\n",
    "X_test = X_test.reshape(51, 224, 224, 3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXvpRUAy6Lt1"
   },
   "source": [
    "## the next step is to define the model that will be trained to recognize covid, normal or Viral Pneumonia from these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 150528)\n",
      "(200, 150528)\n"
     ]
    }
   ],
   "source": [
    "train_vgg_bf = X_train.reshape(X_train.shape[0],-1)\n",
    "valid_vgg_bf = X_test.reshape(X_test.shape[0],-1)\n",
    "print (valid_vgg_bf.shape)\n",
    "print (train_vgg_bf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation VGG LogLoss 1.1669545136449881\n",
      "Validation VGG Accuracy 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "compare_loss={}\n",
    "compare_accuracy = {}\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=147)\n",
    "logreg.fit(train_vgg_bf, (y_train * range(Num_Class)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(valid_vgg_bf)\n",
    "valid_preds = logreg.predict(valid_vgg_bf)\n",
    "compare_loss['Vgg16']=log_loss(y_test, valid_probs)\n",
    "compare_accuracy['Vgg16']=accuracy_score((y_test * range(Num_Class)).sum(axis=1), valid_preds)\n",
    "print('Validation VGG LogLoss {}'.format(compare_loss['Vgg16']))\n",
    "print('Validation VGG Accuracy {}'.format(compare_accuracy['Vgg16']))\n",
    "y_lr_test = (y_test * range(Num_Class)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8823529411764706\n",
      "F1 score: 0.8833402260821615\n",
      "Recall: 0.8838665290677675\n",
      "Precision: 0.8911764705882352\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87        15\n",
      "           1       1.00      0.82      0.90        17\n",
      "           2       0.85      0.89      0.87        19\n",
      "\n",
      "    accuracy                           0.88        51\n",
      "   macro avg       0.89      0.88      0.88        51\n",
      "weighted avg       0.89      0.88      0.88        51\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[14  0  1]\n",
      " [ 1 14  2]\n",
      " [ 2  0 17]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print ('Accuracy:', accuracy_score(y_lr_test, valid_preds))\n",
    "print ('F1 score:', f1_score(y_lr_test, valid_preds, average='macro'))\n",
    "print ('Recall:', recall_score(y_lr_test, valid_preds, average='macro'))\n",
    "print ('Precision:', precision_score(y_lr_test, valid_preds, average='macro'))\n",
    "print ('\\n clasification report:\\n', classification_report(y_lr_test,valid_preds))\n",
    "print ('\\n confussion matrix:\\n',confusion_matrix(y_lr_test, valid_preds))\n",
    "\n",
    "X = train_vgg_bf\n",
    "numpy_labels = y_train\n",
    "numpy_all = logreg.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sillouette Score using K-Means 0.1567434865534098\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b9fca61cc959>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# print (\"Sillouette Score using GMM\", score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mplot_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./embeddings_plot.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-ab1cbdf8a98c>\u001b[0m in \u001b[0;36mplot_mnist\u001b[0;34m(numpy_all, numpy_labels, name)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_labels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'covid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'normal'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'viral pnemonia'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "clusterer = KMeans(n_clusters=3)\n",
    "preds = clusterer.fit_predict(X)\n",
    "centers = clusterer.cluster_centers_\n",
    "score = silhouette_score(X, preds)\n",
    "print (\"Sillouette Score using K-Means\", score)\n",
    "\n",
    "\n",
    "# from sklearn.mixture import GaussianMixture\n",
    "# gm = GaussianMixture(n_components=3, random_state=0).fit(X)\n",
    "# preds = gm.predict(X)\n",
    "# score = silhouette_score(X, preds)\n",
    "# print (\"Sillouette Score using GMM\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 17s 83ms/step\n",
      "51/51 [==============================] - 5s 90ms/step\n",
      "VGG train bottleneck features shape: (200, 512) size: 102,400\n",
      "VGG valid bottleneck features shape: (51, 512) size: 26,112\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "POOLING = 'avg'\n",
    "vgg_bottleneck = VGG16(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_vgg_bf = vgg_bottleneck.predict(X_train, batch_size=32, verbose=1)\n",
    "valid_vgg_bf = vgg_bottleneck.predict(X_test, batch_size=32, verbose=1)\n",
    "print('VGG train bottleneck features shape: {} size: {:,}'.format(train_vgg_bf.shape, train_vgg_bf.size))\n",
    "print('VGG valid bottleneck features shape: {} size: {:,}'.format(valid_vgg_bf.shape, valid_vgg_bf.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation VGG LogLoss 0.44055241175848586\n",
      "Validation VGG Accuracy 0.9215686274509803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "compare_loss={}\n",
    "compare_accuracy = {}\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=147)\n",
    "logreg.fit(train_vgg_bf, (y_train * range(Num_Class)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(valid_vgg_bf)\n",
    "valid_preds = logreg.predict(valid_vgg_bf)\n",
    "compare_loss['Vgg16']=log_loss(y_test, valid_probs)\n",
    "compare_accuracy['Vgg16']=accuracy_score((y_test * range(Num_Class)).sum(axis=1), valid_preds)\n",
    "print('Validation VGG LogLoss {}'.format(compare_loss['Vgg16']))\n",
    "print('Validation VGG Accuracy {}'.format(compare_accuracy['Vgg16']))\n",
    "y_tl_test = (y_test * range(Num_Class)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9215686274509803\n",
      "F1 score: 0.9180555555555556\n",
      "Recall: 0.9215686274509803\n",
      "Precision: 0.9290382819794584\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        15\n",
      "           1       1.00      0.76      0.87        17\n",
      "           2       0.90      1.00      0.95        19\n",
      "\n",
      "    accuracy                           0.92        51\n",
      "   macro avg       0.93      0.92      0.92        51\n",
      "weighted avg       0.93      0.92      0.92        51\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[15  0  0]\n",
      " [ 2 13  2]\n",
      " [ 0  0 19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import f1_score\n",
    "print ('Accuracy:', accuracy_score(y_tl_test, valid_preds))\n",
    "print ('F1 score:', f1_score(y_tl_test, valid_preds, average='macro'))\n",
    "print ('Recall:', recall_score(y_tl_test, valid_preds, average='macro'))\n",
    "print ('Precision:', precision_score(y_tl_test, valid_preds, average='macro'))\n",
    "print ('\\n clasification report:\\n', classification_report(y_tl_test,valid_preds))\n",
    "print ('\\n confussion matrix:\\n',confusion_matrix(y_tl_test, valid_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HCO_BTMI6R9w"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2), \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(), \n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'), \n",
    "    tf.keras.layers.Dense(3, activation='softmax')  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0AKNu0586zHF",
    "outputId": "84ad4b5f-6d4a-4dfc-8fd9-0a717a643abf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               9470464   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 9,495,587\n",
      "Trainable params: 9,495,587\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FEgt8B7E61SB"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "t0DxfA_g7MAL",
    "outputId": "4293ecd9-2d11-4917-ecdd-167063f05839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 251 images belonging to 3 classes.\n",
      "Found 66 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255.\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# --------------------\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "# --------------------\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(150, 150))     \n",
    "# --------------------\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "# --------------------\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'categorical',\n",
    "                                                         target_size = (150, 150),\n",
    "                                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "VRdUphDd7cIG",
    "outputId": "8f47a779-f134-4238-decd-8a715c7cface"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 10 steps, validate for 3 steps\n",
      "Epoch 1/20\n",
      "10/10 - 9s - loss: 1.4507 - accuracy: 0.3246 - val_loss: 0.9754 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "10/10 - 9s - loss: 0.8378 - accuracy: 0.7225 - val_loss: 0.6352 - val_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "10/10 - 9s - loss: 0.3404 - accuracy: 0.8691 - val_loss: 0.5681 - val_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "10/10 - 9s - loss: 0.2473 - accuracy: 0.9110 - val_loss: 0.5623 - val_accuracy: 0.8333\n",
      "Epoch 5/20\n",
      "10/10 - 9s - loss: 0.2324 - accuracy: 0.9110 - val_loss: 0.6192 - val_accuracy: 0.7667\n",
      "Epoch 6/20\n",
      "10/10 - 9s - loss: 0.2279 - accuracy: 0.9300 - val_loss: 0.7814 - val_accuracy: 0.7167\n",
      "Epoch 7/20\n",
      "10/10 - 9s - loss: 0.1542 - accuracy: 0.9424 - val_loss: 0.2892 - val_accuracy: 0.8667\n",
      "Epoch 8/20\n",
      "10/10 - 8s - loss: 0.1170 - accuracy: 0.9550 - val_loss: 0.4771 - val_accuracy: 0.8167\n",
      "Epoch 9/20\n",
      "10/10 - 9s - loss: 0.0784 - accuracy: 0.9738 - val_loss: 0.2287 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "10/10 - 8s - loss: 0.0501 - accuracy: 0.9895 - val_loss: 0.2307 - val_accuracy: 0.9167\n",
      "Epoch 11/20\n",
      "10/10 - 8s - loss: 0.0308 - accuracy: 0.9948 - val_loss: 0.1454 - val_accuracy: 0.9500\n",
      "Epoch 12/20\n",
      "10/10 - 8s - loss: 0.0408 - accuracy: 0.9843 - val_loss: 0.2977 - val_accuracy: 0.8833\n",
      "Epoch 13/20\n",
      "10/10 - 9s - loss: 0.0284 - accuracy: 0.9948 - val_loss: 0.1337 - val_accuracy: 0.9167\n",
      "Epoch 14/20\n",
      "10/10 - 9s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9167\n",
      "Epoch 15/20\n",
      "10/10 - 9s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9000\n",
      "Epoch 16/20\n",
      "10/10 - 9s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.9167\n",
      "Epoch 17/20\n",
      "10/10 - 8s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9000\n",
      "Epoch 18/20\n",
      "10/10 - 9s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9333\n",
      "Epoch 19/20\n",
      "10/10 - 9s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9167\n",
      "Epoch 20/20\n",
      "10/10 - 9s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.8833\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                              validation_data=validation_generator,\n",
    "                              steps_per_epoch=10,\n",
    "                              epochs=20,\n",
    "                              validation_steps = 3,\n",
    "                              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 426ms/step\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 2 1 1 1 2 1\n",
      " 1 1 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        26\n",
      "           1       0.89      0.85      0.87        20\n",
      "           2       0.90      0.90      0.90        20\n",
      "\n",
      "    accuracy                           0.92        66\n",
      "   macro avg       0.92      0.92      0.92        66\n",
      "weighted avg       0.92      0.92      0.92        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(validation_generator, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "# print (y_test)\n",
    "from sklearn import preprocessing\n",
    "pre = preprocessing.LabelEncoder()\n",
    "pre.fit(y_test)\n",
    "labels = pre.transform(y_test)\n",
    "print (validation_generator.classes)\n",
    "print (y_pred_bool)\n",
    "# \n",
    "print(classification_report(validation_generator.classes, y_pred_bool))\n",
    "\n",
    "numpy_labels = labels\n",
    "numpy_all = logreg.coef_\n",
    "print (numpy_all)\n",
    "clusterer = KMeans(n_clusters=3)\n",
    "preds = clusterer.fit_predict(X)\n",
    "centers = clusterer.cluster_centers_\n",
    "score = silhouette_score(X, preds)\n",
    "print (\"Sillouette Score using CNN approach\", score)\n",
    "# plot_mnist(numpy_all, numpy_labels,name=\"./embeddings_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9215686274509803\n",
      "F1 score: 0.9180555555555556\n",
      "Recall: 0.9215686274509803\n",
      "Precision: 0.9290382819794584\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        15\n",
      "           1       1.00      0.76      0.87        17\n",
      "           2       0.90      1.00      0.95        19\n",
      "\n",
      "    accuracy                           0.92        51\n",
      "   macro avg       0.93      0.92      0.92        51\n",
      "weighted avg       0.93      0.92      0.92        51\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[15  0  0]\n",
      " [ 2 13  2]\n",
      " [ 0  0 19]]\n"
     ]
    }
   ],
   "source": [
    "y_test = (y_test * range(3)).sum(axis=1)\n",
    "print ('Accuracy:', accuracy_score(y_test, valid_preds))\n",
    "print ('F1 score:', f1_score(y_test, valid_preds, average='macro'))\n",
    "print ('Recall:', recall_score(y_test, valid_preds, average='macro'))\n",
    "print ('Precision:', precision_score(y_test, valid_preds, average='macro'))\n",
    "print ('\\n clasification report:\\n', classification_report(y_test,valid_preds))\n",
    "print ('\\n confussion matrix:\\n',confusion_matrix(y_test, valid_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
